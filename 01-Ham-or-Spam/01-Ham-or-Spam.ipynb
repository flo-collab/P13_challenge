{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ham or Spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fuetu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fuetu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fuetu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when installing nltk for the first time we need to also download a few built in libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5728, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"emails.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is made up of email that are classified as ham [0] or spam[1]. You need to clean the dataset before training a prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Create a function to remove the punctuation. Apply it to the entire data and add the output as a new column in the dataframe called `clean_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stuff(string:str,stuff_to_remove:str):\n",
    "    stuff_to_remove = stuff_to_remove\n",
    "    for letter in string:\n",
    "        if letter in stuff_to_remove:\n",
    "            string = string.replace(letter,'')\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject 4 color printing special  request addi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>subject re  research and development charges t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>subject re  receipts from visit  jim   thanks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>subject re  enron case study update  wow  all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>subject re  interest  david   please  call shi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>subject news  aurora 5  2 update  aurora versi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     subject naturally irresistible your corporate ...     1\n",
       "1     subject the stock trading gunslinger  fanny is...     1\n",
       "2     subject unbelievable new homes made easy  im w...     1\n",
       "3     subject 4 color printing special  request addi...     1\n",
       "4     subject do not have money  get software cds fr...     1\n",
       "...                                                 ...   ...\n",
       "5723  subject re  research and development charges t...     0\n",
       "5724  subject re  receipts from visit  jim   thanks ...     0\n",
       "5725  subject re  enron case study update  wow  all ...     0\n",
       "5726  subject re  interest  david   please  call shi...     0\n",
       "5727  subject news  aurora 5  2 update  aurora versi...     0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(string):\n",
    "    punctuation = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for letter in string:\n",
    "        if letter in punctuation:\n",
    "            string = string.replace(letter,'')\n",
    "    return string\n",
    "df['text'] = df['text'].apply(remove_punctuation)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject: do not have money , get software cds'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"\"\"Subject: do not have money , get software cds\"\"\"\n",
    "test.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Create a function to lower case the text. Apply it to `clean_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject 4 color printing special  request addi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>subject re  research and development charges t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>subject re  receipts from visit  jim   thanks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>subject re  enron case study update  wow  all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>subject re  interest  david   please  call shi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>subject news  aurora 5  2 update  aurora versi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     subject naturally irresistible your corporate ...     1\n",
       "1     subject the stock trading gunslinger  fanny is...     1\n",
       "2     subject unbelievable new homes made easy  im w...     1\n",
       "3     subject 4 color printing special  request addi...     1\n",
       "4     subject do not have money  get software cds fr...     1\n",
       "...                                                 ...   ...\n",
       "5723  subject re  research and development charges t...     0\n",
       "5724  subject re  receipts from visit  jim   thanks ...     0\n",
       "5725  subject re  enron case study update  wow  all ...     0\n",
       "5726  subject re  interest  david   please  call shi...     0\n",
       "5727  subject news  aurora 5  2 update  aurora versi...     0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Create a function to remove numbers from the text. Apply it to `clean_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([str(i) for i in range(10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject  color printing special  request addit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>subject re  research and development charges t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>subject re  receipts from visit  jim   thanks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>subject re  enron case study update  wow  all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>subject re  interest  david   please  call shi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>subject news  aurora    update  aurora version...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     subject naturally irresistible your corporate ...     1\n",
       "1     subject the stock trading gunslinger  fanny is...     1\n",
       "2     subject unbelievable new homes made easy  im w...     1\n",
       "3     subject  color printing special  request addit...     1\n",
       "4     subject do not have money  get software cds fr...     1\n",
       "...                                                 ...   ...\n",
       "5723  subject re  research and development charges t...     0\n",
       "5724  subject re  receipts from visit  jim   thanks ...     0\n",
       "5725  subject re  enron case study update  wow  all ...     0\n",
       "5726  subject re  interest  david   please  call shi...     0\n",
       "5727  subject news  aurora    update  aurora version...     0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(remove_stuff, stuff_to_remove = '0123456789')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Create a function to remove stopwords from the text. Apply it to `clean_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject naturally irresistible your corporate identity  lt is really hard to recollect a company  the  market is full of suqgestions and the information isoverwhelminq  but a good  catchy logo  stylish statlonery and outstanding website  will make the task much easier   we do not promise that havinq ordered a iogo your  company will automaticaily become a world ieader  it isguite ciear that  without good products  effective business organization and practicable aim it  will be hotat nowadays market  but we do promise that your marketing efforts  will become much more effective  here is the list of clear  benefits  creativeness  hand  made  original logos  specially done  to reflect your distinctive company image  convenience  logo and stationery  are provided in all formats  easy  to  use content management system letsyou  change your website content and even its structure  promptness  you  will see logo drafts within three business days  affordability  your  marketing break  through shouldn  t make gaps in your budget    satisfaction  guaranteed  we provide unlimited amount of changes with no extra fees for you to  be surethat you will love the result of this collaboration  have a look at our  portfolio                                                     not interested                                                       '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lala = df['text'][0]\n",
    "lala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "print('re' in nltk.corpus.stopwords.words('english'),'subject' in nltk.corpus.stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopword(string:str):\n",
    "    temp = string.split(' ')\n",
    "    out=[]\n",
    "    for w in temp:\n",
    "        if w not in nltk.corpus.stopwords.words('english'):\n",
    "            #print(w)\n",
    "            out.append(w)\n",
    "    return ' '.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject naturally irresistible corporate identity  lt really hard recollect company   market full suqgestions information isoverwhelminq  good  catchy logo  stylish statlonery outstanding website  make task much easier   promise havinq ordered iogo  company automaticaily become world ieader  isguite ciear  without good products  effective business organization practicable aim  hotat nowadays market  promise marketing efforts  become much effective  list clear  benefits  creativeness  hand  made  original logos  specially done  reflect distinctive company image  convenience  logo stationery  provided formats  easy   use content management system letsyou  change website content even structure  promptness   see logo drafts within three business days  affordability   marketing break   make gaps budget    satisfaction  guaranteed  provide unlimited amount changes extra fees  surethat love result collaboration  look  portfolio                                                     interested                                                       '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_stopword(lala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject naturally irresistible corporate ident...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject stock trading gunslinger  fanny merril...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject  color printing special  request addit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject money  get software cds   software com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>subject  research development charges gpg     ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>subject  receipts visit  jim   thanks invitati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>subject  enron case study update  wow  day   s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>subject  interest  david   please  call shirle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>subject news  aurora    update  aurora version...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     subject naturally irresistible corporate ident...     1\n",
       "1     subject stock trading gunslinger  fanny merril...     1\n",
       "2     subject unbelievable new homes made easy  im w...     1\n",
       "3     subject  color printing special  request addit...     1\n",
       "4     subject money  get software cds   software com...     1\n",
       "...                                                 ...   ...\n",
       "5723  subject  research development charges gpg     ...     0\n",
       "5724  subject  receipts visit  jim   thanks invitati...     0\n",
       "5725  subject  enron case study update  wow  day   s...     0\n",
       "5726  subject  interest  david   please  call shirle...     0\n",
       "5727  subject news  aurora    update  aurora version...     0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(filter_stopword)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Create a function to lemmatize the text. Make sure the output is a single string, not a list of words. Apply it to `clean_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lemm(stuff:str):\n",
    "    list_stuff = stuff.split(\" \")\n",
    "    for i in range(len(list_stuff)):\n",
    "        list_stuff[i] = lemmatizer.lemmatize(list_stuff[i])\n",
    "    result = ' '.join(list_stuff)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'rocks subject naturally irresistible your corporate identity  lt is really hard to recollect a company  the  market is full of suqgestions and the information isoverwhelminq  but a good  catchy logo  stylish statlonery and outstanding website  will make the task much easier   we do not promise that havinq ordered a iogo your  company will automaticaily become a world ieader  it isguite ciear that  without good products  effective business organization and practicable aim it  will be hotat nowadays market  but we do promise that your marketing efforts  will become much more effective  here is the list of clear  benefits  creativeness  hand  made  original logos  specially done  to reflect your distinctive company image  convenience  logo and stationery  are provided in all formats  easy  to  use content management system letsyou  change your website content and even its structure  promptness  you  will see logo drafts within three business days  affordability  your  marketing break  through shouldn  t make gaps in your budget    satisfaction  guaranteed  we provide unlimited amount of changes with no extra fees for you to  be surethat you will love the result of this collaboration  have a look at our  portfolio  not interested'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rock subject naturally irresistible your corporate identity  lt is really hard to recollect a company  the  market is full of suqgestions and the information isoverwhelminq  but a good  catchy logo  stylish statlonery and outstanding website  will make the task much easier   we do not promise that havinq ordered a iogo your  company will automaticaily become a world ieader  it isguite ciear that  without good product  effective business organization and practicable aim it  will be hotat nowadays market  but we do promise that your marketing effort  will become much more effective  here is the list of clear  benefit  creativeness  hand  made  original logo  specially done  to reflect your distinctive company image  convenience  logo and stationery  are provided in all format  easy  to  use content management system letsyou  change your website content and even it structure  promptness  you  will see logo draft within three business day  affordability  your  marketing break  through shouldn  t make gap in your budget    satisfaction  guaranteed  we provide unlimited amount of change with no extra fee for you to  be surethat you will love the result of this collaboration  have a look at our  portfolio  not interested'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_lemm(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "troubl\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "print(porter.stem(\"troubling\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject naturally irresistible corporate ident...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject stock trading gunslinger  fanny merril...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject unbelievable new home made easy  im wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject  color printing special  request addit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject money  get software cd   software comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>subject  research development charge gpg      ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>subject  receipt visit  jim   thanks invitatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>subject  enron case study update  wow  day   s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>subject  interest  david   please  call shirle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>subject news  aurora    update  aurora version...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     subject naturally irresistible corporate ident...     1\n",
       "1     subject stock trading gunslinger  fanny merril...     1\n",
       "2     subject unbelievable new home made easy  im wa...     1\n",
       "3     subject  color printing special  request addit...     1\n",
       "4     subject money  get software cd   software comp...     1\n",
       "...                                                 ...   ...\n",
       "5723  subject  research development charge gpg      ...     0\n",
       "5724  subject  receipt visit  jim   thanks invitatio...     0\n",
       "5725  subject  enron case study update  wow  day   s...     0\n",
       "5726  subject  interest  david   please  call shirle...     0\n",
       "5727  subject news  aurora    update  aurora version...     0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(make_lemm)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Vectorize the `clean_text` to a Bag-of-Words representation with a default CountVectorizer . Save as `X_bow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the feature matrix \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "matrix = CountVectorizer(max_features=1000)\n",
    "X_bow = matrix.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fuetu\\.virtualenvs\\P13_challenge-2YT7P2w5\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'able',\n",
       " 'academic',\n",
       " 'access',\n",
       " 'account',\n",
       " 'accounting',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'add',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adobe',\n",
       " 'advance',\n",
       " 'advice',\n",
       " 'afternoon',\n",
       " 'agenda',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreement',\n",
       " 'alex',\n",
       " 'allow',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'america',\n",
       " 'american',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'andrew',\n",
       " 'anita',\n",
       " 'anjam',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'aol',\n",
       " 'application',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'approved',\n",
       " 'april',\n",
       " 'area',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'article',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asset',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'attached',\n",
       " 'attachment',\n",
       " 'attend',\n",
       " 'auction',\n",
       " 'august',\n",
       " 'austin',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'average',\n",
       " 'away',\n",
       " 'back',\n",
       " 'background',\n",
       " 'bank',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basis',\n",
       " 'baylor',\n",
       " 'become',\n",
       " 'begin',\n",
       " 'believe',\n",
       " 'ben',\n",
       " 'benefit',\n",
       " 'berkeley',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'billion',\n",
       " 'bit',\n",
       " 'board',\n",
       " 'bob',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'box',\n",
       " 'bring',\n",
       " 'brown',\n",
       " 'budget',\n",
       " 'build',\n",
       " 'building',\n",
       " 'business',\n",
       " 'buy',\n",
       " 'ca',\n",
       " 'calendar',\n",
       " 'california',\n",
       " 'call',\n",
       " 'called',\n",
       " 'campus',\n",
       " 'candidate',\n",
       " 'cannot',\n",
       " 'cap',\n",
       " 'capacity',\n",
       " 'capital',\n",
       " 'card',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cc',\n",
       " 'cd',\n",
       " 'cell',\n",
       " 'center',\n",
       " 'cera',\n",
       " 'certain',\n",
       " 'chair',\n",
       " 'chairman',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'chapter',\n",
       " 'charge',\n",
       " 'check',\n",
       " 'chief',\n",
       " 'choice',\n",
       " 'chris',\n",
       " 'christie',\n",
       " 'city',\n",
       " 'class',\n",
       " 'clear',\n",
       " 'click',\n",
       " 'client',\n",
       " 'close',\n",
       " 'co',\n",
       " 'code',\n",
       " 'colleague',\n",
       " 'com',\n",
       " 'come',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'commercial',\n",
       " 'commission',\n",
       " 'committee',\n",
       " 'commodity',\n",
       " 'communication',\n",
       " 'company',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'computer',\n",
       " 'concern',\n",
       " 'conference',\n",
       " 'confidential',\n",
       " 'confirm',\n",
       " 'confirmation',\n",
       " 'consumer',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'continue',\n",
       " 'contract',\n",
       " 'control',\n",
       " 'convenience',\n",
       " 'coordinate',\n",
       " 'coordinator',\n",
       " 'copy',\n",
       " 'corp',\n",
       " 'corporate',\n",
       " 'corporation',\n",
       " 'correlation',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'cover',\n",
       " 'create',\n",
       " 'credit',\n",
       " 'crenshaw',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'curve',\n",
       " 'customer',\n",
       " 'dabhol',\n",
       " 'daily',\n",
       " 'dale',\n",
       " 'data',\n",
       " 'database',\n",
       " 'date',\n",
       " 'david',\n",
       " 'day',\n",
       " 'de',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'debt',\n",
       " 'december',\n",
       " 'decision',\n",
       " 'default',\n",
       " 'delivery',\n",
       " 'demand',\n",
       " 'department',\n",
       " 'dept',\n",
       " 'derivative',\n",
       " 'design',\n",
       " 'desk',\n",
       " 'detail',\n",
       " 'develop',\n",
       " 'developed',\n",
       " 'developing',\n",
       " 'development',\n",
       " 'different',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'director',\n",
       " 'discount',\n",
       " 'discus',\n",
       " 'discussed',\n",
       " 'discussion',\n",
       " 'distribution',\n",
       " 'doc',\n",
       " 'document',\n",
       " 'dollar',\n",
       " 'done',\n",
       " 'download',\n",
       " 'dpc',\n",
       " 'dr',\n",
       " 'draft',\n",
       " 'drive',\n",
       " 'due',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'easy',\n",
       " 'eb',\n",
       " 'economic',\n",
       " 'economics',\n",
       " 'ect',\n",
       " 'edu',\n",
       " 'ee',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effort',\n",
       " 'either',\n",
       " 'electric',\n",
       " 'electricity',\n",
       " 'electronic',\n",
       " 'else',\n",
       " 'email',\n",
       " 'employee',\n",
       " 'ena',\n",
       " 'end',\n",
       " 'energy',\n",
       " 'engine',\n",
       " 'engineering',\n",
       " 'enron',\n",
       " 'enronxgate',\n",
       " 'enter',\n",
       " 'equipment',\n",
       " 'equity',\n",
       " 'eric',\n",
       " 'error',\n",
       " 'estimate',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'europe',\n",
       " 'european',\n",
       " 'evaluation',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'example',\n",
       " 'exchange',\n",
       " 'executive',\n",
       " 'existing',\n",
       " 'expect',\n",
       " 'expected',\n",
       " 'expense',\n",
       " 'experience',\n",
       " 'fact',\n",
       " 'factor',\n",
       " 'faculty',\n",
       " 'fall',\n",
       " 'family',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'fax',\n",
       " 'feature',\n",
       " 'feb',\n",
       " 'february',\n",
       " 'fee',\n",
       " 'feedback',\n",
       " 'feel',\n",
       " 'ferc',\n",
       " 'field',\n",
       " 'file',\n",
       " 'final',\n",
       " 'finance',\n",
       " 'financial',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'firm',\n",
       " 'first',\n",
       " 'fit',\n",
       " 'fixed',\n",
       " 'floor',\n",
       " 'flow',\n",
       " 'focus',\n",
       " 'follow',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'forecast',\n",
       " 'form',\n",
       " 'forward',\n",
       " 'forwarded',\n",
       " 'found',\n",
       " 'four',\n",
       " 'free',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'front',\n",
       " 'fuel',\n",
       " 'full',\n",
       " 'function',\n",
       " 'fund',\n",
       " 'future',\n",
       " 'fw',\n",
       " 'fyi',\n",
       " 'garp',\n",
       " 'gas',\n",
       " 'general',\n",
       " 'generation',\n",
       " 'george',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'gibner',\n",
       " 'give',\n",
       " 'given',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'global',\n",
       " 'go',\n",
       " 'goal',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'government',\n",
       " 'graduate',\n",
       " 'grant',\n",
       " 'great',\n",
       " 'greg',\n",
       " 'group',\n",
       " 'growth',\n",
       " 'guarantee',\n",
       " 'guy',\n",
       " 'hand',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'hearing',\n",
       " 'held',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'henwood',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'historical',\n",
       " 'holiday',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'hotel',\n",
       " 'hou',\n",
       " 'hour',\n",
       " 'house',\n",
       " 'houston',\n",
       " 'however',\n",
       " 'hr',\n",
       " 'html',\n",
       " 'http',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'image',\n",
       " 'immediately',\n",
       " 'impact',\n",
       " 'important',\n",
       " 'inc',\n",
       " 'include',\n",
       " 'included',\n",
       " 'includes',\n",
       " 'including',\n",
       " 'income',\n",
       " 'increase',\n",
       " 'india',\n",
       " 'individual',\n",
       " 'industrial',\n",
       " 'industry',\n",
       " 'info',\n",
       " 'information',\n",
       " 'input',\n",
       " 'insurance',\n",
       " 'intended',\n",
       " 'interest',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'international',\n",
       " 'internet',\n",
       " 'internship',\n",
       " 'interview',\n",
       " 'investment',\n",
       " 'investor',\n",
       " 'invitation',\n",
       " 'invite',\n",
       " 'involved',\n",
       " 'iris',\n",
       " 'iso',\n",
       " 'issue',\n",
       " 'item',\n",
       " 'james',\n",
       " 'jan',\n",
       " 'january',\n",
       " 'jeff',\n",
       " 'jim',\n",
       " 'jinbaek',\n",
       " 'job',\n",
       " 'joe',\n",
       " 'john',\n",
       " 'join',\n",
       " 'jones',\n",
       " 'jul',\n",
       " 'julie',\n",
       " 'july',\n",
       " 'june',\n",
       " 'kaminski',\n",
       " 'keep',\n",
       " 'ken',\n",
       " 'kevin',\n",
       " 'key',\n",
       " 'kim',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'knowledge',\n",
       " 'krishna',\n",
       " 'krishnarao',\n",
       " 'kristin',\n",
       " 'la',\n",
       " 'large',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'le',\n",
       " 'lead',\n",
       " 'leading',\n",
       " 'learn',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'left',\n",
       " 'legal',\n",
       " 'lender',\n",
       " 'leppard',\n",
       " 'let',\n",
       " 'letter',\n",
       " 'level',\n",
       " 'license',\n",
       " 'life',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'limited',\n",
       " 'line',\n",
       " 'link',\n",
       " 'list',\n",
       " 'listed',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lng',\n",
       " 'load',\n",
       " 'loan',\n",
       " 'location',\n",
       " 'logo',\n",
       " 'lon',\n",
       " 'london',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'loss',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'low',\n",
       " 'lu',\n",
       " 'lunch',\n",
       " 'machine',\n",
       " 'mack',\n",
       " 'made',\n",
       " 'maharashtra',\n",
       " 'mail',\n",
       " 'mailing',\n",
       " 'mailto',\n",
       " 'main',\n",
       " 'major',\n",
       " 'make',\n",
       " 'making',\n",
       " 'management',\n",
       " 'manager',\n",
       " 'managing',\n",
       " 'many',\n",
       " 'march',\n",
       " 'margaret',\n",
       " 'mark',\n",
       " 'market',\n",
       " 'marketing',\n",
       " 'martin',\n",
       " 'masson',\n",
       " 'material',\n",
       " 'matter',\n",
       " 'maureen',\n",
       " 'may',\n",
       " 'mba',\n",
       " 'mean',\n",
       " 'measure',\n",
       " 'medium',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'member',\n",
       " 'membership',\n",
       " 'mentioned',\n",
       " 'message',\n",
       " 'metal',\n",
       " 'method',\n",
       " 'methodology',\n",
       " 'michael',\n",
       " 'mid',\n",
       " 'might',\n",
       " 'mike',\n",
       " 'million',\n",
       " 'mind',\n",
       " 'minute',\n",
       " 'model',\n",
       " 'modeling',\n",
       " 'molly',\n",
       " 'monday',\n",
       " 'money',\n",
       " 'month',\n",
       " 'monthly',\n",
       " 'moore',\n",
       " 'morning',\n",
       " 'move',\n",
       " 'moving',\n",
       " 'mr',\n",
       " 'mseb',\n",
       " 'much',\n",
       " 'must',\n",
       " 'na',\n",
       " 'name',\n",
       " 'national',\n",
       " 'natural',\n",
       " 'nd',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'net',\n",
       " 'network',\n",
       " 'never',\n",
       " 'new',\n",
       " 'news',\n",
       " 'newsletter',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'nick',\n",
       " 'night',\n",
       " 'non',\n",
       " 'north',\n",
       " 'note',\n",
       " 'notice',\n",
       " 'nov',\n",
       " 'november',\n",
       " 'number',\n",
       " 'oct',\n",
       " 'october',\n",
       " 'offer',\n",
       " 'office',\n",
       " 'official',\n",
       " 'oil',\n",
       " 'ok',\n",
       " 'one',\n",
       " 'online',\n",
       " 'open',\n",
       " 'operating',\n",
       " 'operation',\n",
       " 'opportunity',\n",
       " 'option',\n",
       " 'order',\n",
       " 'oren',\n",
       " 'org',\n",
       " 'organization',\n",
       " 'original',\n",
       " 'others',\n",
       " 'outside',\n",
       " 'package',\n",
       " 'page',\n",
       " 'paid',\n",
       " 'panel',\n",
       " 'paper',\n",
       " 'part',\n",
       " 'participant',\n",
       " 'participate',\n",
       " 'participation',\n",
       " 'particular',\n",
       " 'partner',\n",
       " 'party',\n",
       " 'password',\n",
       " 'past',\n",
       " 'patrick',\n",
       " 'paul',\n",
       " 'paulo',\n",
       " 'pay',\n",
       " 'payment',\n",
       " 'pc',\n",
       " 'pdf',\n",
       " 'people',\n",
       " 'pep',\n",
       " 'per',\n",
       " 'performance',\n",
       " 'period',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'ph',\n",
       " 'phase',\n",
       " 'phone',\n",
       " 'pipeline',\n",
       " 'pjm',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'planning',\n",
       " 'plant',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'pm',\n",
       " 'point',\n",
       " 'policy',\n",
       " 'portfolio',\n",
       " 'position',\n",
       " 'positive',\n",
       " 'possible',\n",
       " 'potential',\n",
       " 'power',\n",
       " 'prc',\n",
       " 'pre',\n",
       " 'present',\n",
       " 'presentation',\n",
       " 'president',\n",
       " 'press',\n",
       " 'previous',\n",
       " 'price',\n",
       " 'pricing',\n",
       " 'prior',\n",
       " 'private',\n",
       " 'pro',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'process',\n",
       " 'product',\n",
       " 'production',\n",
       " 'professional',\n",
       " 'professor',\n",
       " 'profit',\n",
       " 'program',\n",
       " 'project',\n",
       " 'promotion',\n",
       " 'proposal',\n",
       " 'proposed',\n",
       " 'provide',\n",
       " 'provided',\n",
       " 'providing',\n",
       " 'public',\n",
       " 'publication',\n",
       " 'purchase',\n",
       " 'purpose',\n",
       " 'put',\n",
       " 'quality',\n",
       " 'quantitative',\n",
       " 'question',\n",
       " 'quick',\n",
       " 'quite',\n",
       " 'rac',\n",
       " 'range',\n",
       " 'rate',\n",
       " 'rather',\n",
       " 'ravi',\n",
       " 'raymond',\n",
       " 'reach',\n",
       " 'read',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'receiving',\n",
       " 'recent',\n",
       " 'recently',\n",
       " 'recommendation',\n",
       " 'record',\n",
       " 'recruiting',\n",
       " 'reference',\n",
       " 'regard',\n",
       " 'regarding',\n",
       " 'region',\n",
       " 'registration',\n",
       " 'related',\n",
       " 'relationship',\n",
       " 'release',\n",
       " 'remember',\n",
       " 'remove',\n",
       " 'removed',\n",
       " 'reply',\n",
       " 'report',\n",
       " 'reporting',\n",
       " 'representative',\n",
       " 'request',\n",
       " 'requested',\n",
       " 'required',\n",
       " 'requirement',\n",
       " 'research',\n",
       " 'reserve',\n",
       " 'resource',\n",
       " 'respond',\n",
       " 'response',\n",
       " 'responsibility',\n",
       " 'responsible',\n",
       " 'result',\n",
       " 'resume',\n",
       " 'retail',\n",
       " 'return',\n",
       " 'revenue',\n",
       " 'review',\n",
       " 'rice',\n",
       " 'richard',\n",
       " 'rick',\n",
       " 'right',\n",
       " 'risk',\n",
       " 'robert',\n",
       " 'role',\n",
       " 'room',\n",
       " 'run',\n",
       " 'said',\n",
       " 'sale',\n",
       " 'sandeep',\n",
       " 'saturday',\n",
       " 'save',\n",
       " 'say',\n",
       " 'schedule',\n",
       " 'scheduled',\n",
       " 'school',\n",
       " 'scott',\n",
       " 'search',\n",
       " 'second',\n",
       " 'section',\n",
       " 'sector',\n",
       " 'security',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seems',\n",
       " 'selected',\n",
       " 'sell',\n",
       " 'seminar',\n",
       " 'send',\n",
       " 'sending',\n",
       " 'senior',\n",
       " 'sent',\n",
       " 'september',\n",
       " 'series',\n",
       " 'server',\n",
       " 'service',\n",
       " 'session',\n",
       " 'set',\n",
       " 'several',\n",
       " 'sevil',\n",
       " 'shall',\n",
       " 'shanbhogue',\n",
       " 'shankman',\n",
       " 'share',\n",
       " 'shirley',\n",
       " 'shmuel',\n",
       " 'short',\n",
       " 'show',\n",
       " 'side',\n",
       " 'sign',\n",
       " 'significant',\n",
       " 'simply',\n",
       " 'simulation',\n",
       " 'since',\n",
       " 'sincerely',\n",
       " 'site',\n",
       " 'skill',\n",
       " 'small',\n",
       " 'smith',\n",
       " 'software',\n",
       " 'solution',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'source',\n",
       " 'speak',\n",
       " 'speaker',\n",
       " 'special',\n",
       " 'specific',\n",
       " 'spoke',\n",
       " 'spread',\n",
       " 'spreadsheet',\n",
       " 'st',\n",
       " 'staff',\n",
       " 'stand',\n",
       " 'standard',\n",
       " 'stanford',\n",
       " 'start',\n",
       " 'starting',\n",
       " 'state',\n",
       " 'statement',\n",
       " 'status',\n",
       " 'stay',\n",
       " 'step',\n",
       " 'stephen',\n",
       " 'steve',\n",
       " 'steven',\n",
       " 'still',\n",
       " 'stinson',\n",
       " 'stock',\n",
       " 'stop',\n",
       " 'storage',\n",
       " 'strategy',\n",
       " 'street',\n",
       " 'strong',\n",
       " 'structure',\n",
       " 'student',\n",
       " 'study',\n",
       " 'subject',\n",
       " 'submit',\n",
       " 'subscription',\n",
       " 'success',\n",
       " 'successful',\n",
       " 'suggested',\n",
       " 'suggestion',\n",
       " 'suite',\n",
       " 'summary',\n",
       " 'summer',\n",
       " 'supply',\n",
       " 'support',\n",
       " 'sure',\n",
       " 'system',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'tamarchenko',\n",
       " 'tanya',\n",
       " 'tax',\n",
       " 'team',\n",
       " 'technical',\n",
       " 'technology',\n",
       " 'tel',\n",
       " 'telephone',\n",
       " 'tell',\n",
       " 'term',\n",
       " 'termination',\n",
       " 'test',\n",
       " 'texas',\n",
       " 'th',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'therefore',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'thinking',\n",
       " 'third',\n",
       " 'thought',\n",
       " 'thousand',\n",
       " 'three',\n",
       " 'thursday',\n",
       " 'time',\n",
       " 'title',\n",
       " 'today',\n",
       " 'together',\n",
       " 'told',\n",
       " 'tom',\n",
       " 'tomorrow',\n",
       " 'tony',\n",
       " 'tool',\n",
       " 'top',\n",
       " 'topic',\n",
       " 'total',\n",
       " 'touch',\n",
       " 'trade',\n",
       " 'trader',\n",
       " 'trading',\n",
       " 'training',\n",
       " 'transaction',\n",
       " 'transfer',\n",
       " 'transmission',\n",
       " 'travel',\n",
       " 'trip',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'tue',\n",
       " 'tuesday',\n",
       " 'turn',\n",
       " 'two',\n",
       " 'tx',\n",
       " 'type',\n",
       " 'uk',\n",
       " 'understand',\n",
       " 'understanding',\n",
       " 'unit',\n",
       " 'united',\n",
       " 'university',\n",
       " 'unsubscribe',\n",
       " 'update',\n",
       " 'upenn',\n",
       " 'upon',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'user',\n",
       " 'using',\n",
       " 'ut',\n",
       " 'utility',\n",
       " 'vacation',\n",
       " 'valuation',\n",
       " 'value',\n",
       " 'var',\n",
       " 'various',\n",
       " 'vasant',\n",
       " 'version',\n",
       " 'via',\n",
       " 'viagra',\n",
       " 'vice',\n",
       " 'video',\n",
       " 'view',\n",
       " 'vince',\n",
       " 'vincent',\n",
       " 'visa',\n",
       " 'visit',\n",
       " 'vkamins',\n",
       " 'voice',\n",
       " 'volatility',\n",
       " 'volume',\n",
       " 'wait',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'way',\n",
       " 'weather',\n",
       " 'web',\n",
       " 'website',\n",
       " 'wednesday',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'west',\n",
       " 'wharton',\n",
       " 'whether',\n",
       " 'wholesale',\n",
       " 'window',\n",
       " 'wish',\n",
       " 'within',\n",
       " 'without',\n",
       " 'word',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'working',\n",
       " 'workshop',\n",
       " 'world',\n",
       " 'worldwide',\n",
       " 'would',\n",
       " 'write',\n",
       " 'writing',\n",
       " 'wrote',\n",
       " 'www',\n",
       " 'yahoo',\n",
       " 'year',\n",
       " 'yes',\n",
       " 'yesterday',\n",
       " 'yet',\n",
       " 'york',\n",
       " 'zimin']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bow = df['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [2, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Cross-validate a MultinomialNB model with the Bag-of-words. Score the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_bow, y_bow, test_size= .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score: \n",
      " 97.16\n",
      "Testing Set Accuracy Score: \n",
      " 97.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)#predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)#accuracy score \n",
    "train_pred_score = accuracy_score(y_train, y_train_pred)\n",
    "test_pred_score = accuracy_score(y_test, y_test_pred)\n",
    "print('Training Set Accuracy Score: \\n', (100 * round(train_pred_score,4)))\n",
    "print('Testing Set Accuracy Score: \\n', (100 * round(test_pred_score,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Please push the exercise once you are done 🙃\n",
    "\n",
    "## 🏁 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
